mdy("March 12, 1975")
parse(25081985)
day(25081985)
mdy(25081985)
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hhmmss("03:22:14")
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
update(this_moment, hours = hour(now()), minutes = minute(now()))
update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
nyc <- now("America/New_York")
nyc
nyc + days(2)
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
getwd()
setwd("../../UCI HAR Dataset")
sub <- read.table("https://s3.amazonaws.com/coursera-uploads/peer-review/7dc8e4b53e763134bbddddbb8daa3507/tidydata.txt",header=FALSE)
sub
View(sub)
#For printing tables in markdown file
#library(pander)
# You should create one R script called run_analysis.R that does the following.
# 1. Merges the training and the test sets to create one data set.
##I'll need this
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
colnames(features) <- c("index","feature")
##testset creation (easier to figure out first because of smaller size)
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt",header=FALSE)
x_test <- read.table("UCI HAR Dataset/test/X_test.txt",header=FALSE)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt",header=FALSE)
test <- cbind(subject_test, y_test, x_test)
colnames(test) <- c("subject","activity",paste(features[,2]))
rm(subject_test,x_test,y_test)
##Create training set
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt",header=FALSE)
x_train <- read.table("UCI HAR Dataset/train/X_train.txt",header=FALSE)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt",header=FALSE)
train <- cbind(subject_train, y_train, x_train)
colnames(train) <- c("subject","activity",paste(features[,2]))
rm(features,subject_train,x_train,y_train)
##Combine training and testing set (suppose training would come first)
bigSet <- rbind(train,test)
rm(train,test)
##Dar she blows
View(bigSet)
str(bigSet)
##Each row is an independent observation of sensor reading over time
##Activities are still repeated, however
Q1 <- bigSet
####################################################################
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("mean()", names(bigSet)) | grepl("std()", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
####################################################################
# 3. Uses descriptive activity names to name the activities in the data set
##activity_labels file is really small and could just be copied and pasted into a switch function. Here ya go.
smallSet$activity<- lapply(smallSet$activity, function(x)switch(x,
"1"= "WALKING",
"2"= "WALKING_UPSTAIRS",
"3"= "WALKING_DOWNSTAIRS",
"4"= "SITTING",
"5"= "STANDING",
"6"= "LAYING"
))
##Convert from list into character
smallSet$activity <- as.character(smallSet$activity)
Q3 <- smallSet$activity
##A much more descriptive activity variable is in there
####################################################################
# 4. Appropriately labels the data set with descriptive variable names.
##I...am pretty sure that I have when I merged the datasets so I could subset later
##But lets do it again
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
index <- (grepl("mean()", features[,2]) | grepl("std()", features[,2]))
newNames <- as.character(features[,2][index])
##Better include subject and activity
newNames <- c("subject","activity",newNames)
colnames(smallSet) <- newNames
rm(features,index,newNames)
Q4 <- names(smallSet)
##They are ugly, but pretty descriptive
####################################################################
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ subject + activity, data= smallSet, mean)
Q5 <- tidy
write.table(tidy,"tidy.txt", row.names=FALSE)
##I'll need this
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
getwd()
swetwd("..")
setwd("..")
##I'll need this
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
colnames(features) <- c("index","feature")
##testset creation (easier to figure out first because of smaller size)
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt",header=FALSE)
x_test <- read.table("UCI HAR Dataset/test/X_test.txt",header=FALSE)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt",header=FALSE)
test <- cbind(subject_test, y_test, x_test)
colnames(test) <- c("subject","activity",paste(features[,2]))
rm(subject_test,x_test,y_test)
##Create training set
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt",header=FALSE)
x_train <- read.table("UCI HAR Dataset/train/X_train.txt",header=FALSE)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt",header=FALSE)
train <- cbind(subject_train, y_train, x_train)
colnames(train) <- c("subject","activity",paste(features[,2]))
rm(features,subject_train,x_train,y_train)
##Combine training and testing set (suppose training would come first)
bigSet <- rbind(train,test)
rm(train,test)
##Dar she blows
View(bigSet)
str(bigSet)
##Each row is an independent observation of sensor reading over time
##Activities are still repeated, however
Q1 <- bigSet
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("mean()", names(bigSet)) | grepl("std()", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
smallSet$activity<- lapply(smallSet$activity, function(x)switch(x,
"1"= "WALKING",
"2"= "WALKING_UPSTAIRS",
"3"= "WALKING_DOWNSTAIRS",
"4"= "SITTING",
"5"= "STANDING",
"6"= "LAYING"
))
##Convert from list into character
smallSet$activity <- as.character(smallSet$activity)
Q3 <- smallSet$activity
##I...am pretty sure that I have when I merged the datasets so I could subset later
##But lets do it again
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
index <- (grepl("mean()", features[,2]) | grepl("std()", features[,2]))
newNames <- as.character(features[,2][index])
##Better include subject and activity
newNames <- c("subject","activity",newNames)
colnames(smallSet) <- newNames
rm(features,index,newNames)
Q4 <- names(smallSet)
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ subject + activity, data= smallSet, mean)
Q5 <- tidy
View(tidy)
sub <- read.table("https://s3.amazonaws.com/coursera-uploads/peer-review/7dc8e4b53e763134bbddddbb8daa3507/tidydata.txt",header=TRUE, sep=",")
View(sub)
sub <- read.table("https://s3.amazonaws.com/coursera-uploads/peer-review/2f5ee64630715e84068f3ba17fd64e4d/tidy.txt",header=TRUE, sep=",")
sub <- read.table("https://s3.amazonaws.com/coursera-uploads/peer-review/2f5ee64630715e84068f3ba17fd64e4d/tidy.txt",header=TRUE)
sub <- read.table("https://s3.amazonaws.com/coursera-uploads/peer-review/bd9ca51ad0d8c4bc5e05049a065922e8/tidydata.txt",header=TRUE)
sub <- read.table("https://s3.amazonaws.com/coursera-uploads/peer-review/bd9ca51ad0d8c4bc5e05049a065922e8/tidydata.txt",header=TRUE, sep = " ")
geetwd()
getwd()
##I...am pretty sure that I have when I merged the datasets so I could subset later
##But lets do it again
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
features
colnames(features) <- c("index","feature")
##testset creation (easier to figure out first because of smaller size)
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt",header=FALSE)
head(subjet_test)
##testset creation (easier to figure out first because of smaller size)
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt",header=FALSE)
head(subject_test)
x_test <- read.table("UCI HAR Dataset/test/X_test.txt",header=FALSE)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt",header=FALSE)
head(x_test)
str(x_test)
dim(features)
dim(x_test)
test <- cbind(subject_test, y_test, x_test)
colnames(test) <- c("subject","activity",paste(features[,2]))
rm(subject_test,x_test,y_test)
##Create training set
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt",header=FALSE)
x_train <- read.table("UCI HAR Dataset/train/X_train.txt",header=FALSE)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt",header=FALSE)
train <- cbind(subject_train, y_train, x_train)
colnames(train) <- c("subject","activity",paste(features[,2]))
rm(features,subject_train,x_train,y_train)
##Combine training and testing set (suppose training would come first)
bigSet <- rbind(train,test)
rm(train,test)
##Dar she blows
View(bigSet)
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("mean()", names(bigSet)) | grepl("std()", names(bigSet)))
targetCols
names(x_test)
names(test)
?grepl
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("mean()", names(bigSet)) | grepl("std()", names(bigSet)))
targetCols
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
names(smallSEt)
names(smallSet)
##Because I am lazy, find me means and stds for me
targetCols <- (grep("*.mean.*" | "*.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
##Because I am lazy, find me means and stds for me
targetCols <- (grep("*.mean.*" | "*.std.*", names(bigSet)))
##Because I am lazy, find me means and stds for me
targetCols <- (grep("*.mean.*" | "*.std.*", features[,2]))
features
##I'll need this
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
colnames(features) <- c("index","feature")
##Because I am lazy, find me means and stds for me
targetCols <- (grep("*.mean.*" | "*.std.*", features[,2]))
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.*" | "*.std.*", features[,2]))
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.* | *.std.*", features[,2]))
targetCols
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.* | *.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ subject + activity, data= smallSet, mean)
Q5 <- tidy
Q5
View(tidy)
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
Q5 <- tidy
write.table(tidy,"tidy.txt", row.names=FALSE)
View(tidy)
# You should create one R script called run_analysis.R that does the following.
# 1. Merges the training and the test sets to create one data set.
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
bigSet$activity <- factor(bigSet$activity, levels = activityLabels[,1], labels = activityLabels[,2])
##Combine training and testing set (suppose training would come first)
bigSet <- rbind(train,test)
bigSet$activity <- factor(bigSet$activity, levels = activityLabels[,1], labels = activityLabels[,2])
# You should create one R script called run_analysis.R that does the following.
# 1. Merges the training and the test sets to create one data set.
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
##I'll need this
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
colnames(features) <- c("index","feature")
##testset creation (easier to figure out first because of smaller size)
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt",header=FALSE)
x_test <- read.table("UCI HAR Dataset/test/X_test.txt",header=FALSE)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt",header=FALSE)
test <- cbind(subject_test, y_test, x_test)
colnames(test) <- c("subject","activity",paste(features[,2]))
rm(subject_test,x_test,y_test)
##Create training set
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt",header=FALSE)
x_train <- read.table("UCI HAR Dataset/train/X_train.txt",header=FALSE)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt",header=FALSE)
train <- cbind(subject_train, y_train, x_train)
colnames(train) <- c("subject","activity",paste(features[,2]))
##Combine training and testing set (suppose training would come first)
bigSet <- rbind(train,test)
bigSet$activity <- factor(bigSet$activity, levels = activityLabels[,1], labels = activityLabels[,2])
rm(train,test)
##Dar she blows
View(bigSet)
##Dar she blows
#View(bigSet)
#str(bigSet)
##Each row is an independent observation of sensor reading over time
##Activities are still repeated, however
Q1 <- bigSet
##Because I am lazy, find me means and stds for me
targetCols <- (grep("*.mean.* | *.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
##Because I am lazy, find me means and stds for me
targetCols <- (grep("*.mean.* | *.std.*", names(bigSet)))
targetCols
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.* | *.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
Q5 <- tidy
write.table(tidy,"tidy.txt", row.names=FALSE)
tidy <- tidy[,c(2,1,3:ncol(tidy))]
getwd()
write.table(tidy,"tidy.txt", row.names=FALSE)
getw()
getwd()
setwd("~/projects/R/courseraGeneral/UCI HAR Dataset/submission")
write.table(tidy,"tidy.txt", row.names=FALSE)
bigSet$subject <- factor(bigSet$subject)
rm(train,test)
##Dar she blows
#View(bigSet)
#str(bigSet)
##Each row is an independent observation of sensor reading over time
##Activities are still repeated, however
Q1 <- bigSet
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.* | *.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
smallSet$activity<- lapply(smallSet$activity, function(x)switch(x,
"1"= "WALKING",
"2"= "WALKING_UPSTAIRS",
"3"= "WALKING_DOWNSTAIRS",
"4"= "SITTING",
"5"= "STANDING",
"6"= "LAYING"
))
##Convert from list into character
smallSet$activity <- as.character(smallSet$activity)
smallSet <- bigSet[,targetCols]
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.* | *.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
tidy <- tidy[,c(2,1,3:ncol(tidy))]
Q5 <- tidy
write.table(tidy,"tidy.txt", row.names=FALSE)
#For printing tables in markdown file
#library(pander)
# You should create one R script called run_analysis.R that does the following.
# 1. Merges the training and the test sets to create one data set.
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
##I'll need this
features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
colnames(features) <- c("index","feature")
##testset creation (easier to figure out first because of smaller size)
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt",header=FALSE)
x_test <- read.table("UCI HAR Dataset/test/X_test.txt",header=FALSE)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt",header=FALSE)
test <- cbind(subject_test, y_test, x_test)
colnames(test) <- c("subject","activity",paste(features[,2]))
rm(subject_test,x_test,y_test)
##Create training set
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt",header=FALSE)
x_train <- read.table("UCI HAR Dataset/train/X_train.txt",header=FALSE)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt",header=FALSE)
train <- cbind(subject_train, y_train, x_train)
colnames(train) <- c("subject","activity",paste(features[,2]))
#rm(features,subject_train,x_train,y_train)
##Combine training and testing set (suppose training would come first)
bigSet <- rbind(train,test)
bigSet$activity <- factor(bigSet$activity, levels = activityLabels[,1], labels = activityLabels[,2])
bigSet$subject <- factor(bigSet$subject)
rm(train,test)
##Dar she blows
#View(bigSet)
#str(bigSet)
##Each row is an independent observation of sensor reading over time
##Activities are still repeated, however
Q1 <- bigSet
####################################################################
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.* | *.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
####################################################################
# 3. Uses descriptive activity names to name the activities in the data set
##activity_labels file is really small and could just be copied and pasted into a switch function. Here ya go.
# smallSet$activity<- lapply(smallSet$activity, function(x)switch(x,
#                                               "1"= "WALKING",
#                                               "2"= "WALKING_UPSTAIRS",
#                                               "3"= "WALKING_DOWNSTAIRS",
#                                               "4"= "SITTING",
#                                               "5"= "STANDING",
#                                               "6"= "LAYING"
# ))
##Convert from list into character
#smallSet$activity <- as.character(smallSet$activity)
#Q3 <- smallSet$activity
##A much more descriptive activity variable is in there
####################################################################
# 4. Appropriately labels the data set with descriptive variable names.
##I...am pretty sure that I have when I merged the datasets so I could subset later
##But lets do it again
#features <- read.table("UCI HAR Dataset/features.txt",header=FALSE)
#index <- (grepl("mean()", features[,2]) | grepl("std()", features[,2]))
#newNames <- as.character(features[,2][index])
##Better include subject and activity
#newNames <- c("subject","activity",newNames)
#colnames(smallSet) <- newNames
#rm(features,index,newNames)
#Q4 <- names(smallSet)
##They are ugly, but pretty descriptive
####################################################################
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
tidy <- tidy[,c(2,1,3:ncol(tidy))]
Q5 <- tidy
write.table(tidy,"tidy.txt", row.names=FALSE)
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
smallSet
names(smallSet)
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
# You should create one R script called run_analysis.R that does the following.
# 1. Merges the training and the test sets to create one data set.
activityLabels <- read.table("activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
##I'll need this
features <- read.table("features.txt",header=FALSE)
colnames(features) <- c("index","feature")
##testset creation (easier to figure out first because of smaller size)
subject_test <- read.table("test/subject_test.txt",header=FALSE)
x_test <- read.table("test/X_test.txt",header=FALSE)
y_test <- read.table("test/y_test.txt",header=FALSE)
test <- cbind(subject_test, y_test, x_test)
colnames(test) <- c("subject","activity",paste(features[,2]))
rm(subject_test,x_test,y_test)
##Create training set
subject_train <- read.table("train/subject_train.txt",header=FALSE)
x_train <- read.table("train/X_train.txt",header=FALSE)
y_train <- read.table("train/y_train.txt",header=FALSE)
train <- cbind(subject_train, y_train, x_train)
colnames(train) <- c("subject","activity",paste(features[,2]))
##Combine training and testing set (suppose training would come first)
bigSet <- rbind(train,test)
bigSet$activity <- factor(bigSet$activity, levels = activityLabels[,1], labels = activityLabels[,2])
bigSet$subject <- factor(bigSet$subject)
rm(train,test)
##Dar she blows
#View(bigSet)
#str(bigSet)
##Each row is an independent observation of sensor reading over time
##Activities are still repeated, however
Q1 <- bigSet
##Because I am lazy, find me means and stds for me
targetCols <- (grepl("*.mean.* | *.std.*", names(bigSet)))
##Better include subject and activity
targetCols[c(1,2)] <- TRUE
smallSet <- bigSet[,targetCols]
rm(targetCols)
##Each observation contains only variables of interest now
Q2 <- smallSet
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy <- aggregate(. ~ activity + subject, data= smallSet, mean)
tidy <- tidy[,c(2,1,3:ncol(tidy))]
Q5 <- tidy
write.table(tidy,"tidy.txt", row.names=FALSE)
